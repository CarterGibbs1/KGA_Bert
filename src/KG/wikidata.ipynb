{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\carte\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from wikidata.client import Client\n",
    "from wikidata.entity import Entity\n",
    "from collections import defaultdict, deque\n",
    "import requests, json\n",
    "import pandas as pd\n",
    "nltk.download('punkt')\n",
    "\n",
    "MAX_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Home', 'Mark Zuckerberg']\n"
     ]
    }
   ],
   "source": [
    "text = \"Home of Mark Zuckerberg is great!\"\n",
    "def get_nouns(sentence):\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    retVal = []\n",
    "    i = 0\n",
    "    while i < len(tags):\n",
    "        key, tag = tags[i]\n",
    "        if 'NN' in tag:\n",
    "            current_noun = key\n",
    "            j = i + 1\n",
    "            while j < len(tags):\n",
    "                key_j, tag_j = tags[j]\n",
    "                if 'NN' in tag_j:\n",
    "                    current_noun = ' '.join([current_noun, key_j])\n",
    "                    j += 1\n",
    "                else:\n",
    "                    i = j - 1\n",
    "                    break\n",
    "            retVal.append(current_noun)\n",
    "            if j == len(tags):\n",
    "                return retVal          \n",
    "        i += 1\n",
    "    return retVal\n",
    "    \n",
    "print(get_nouns(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wikidata_id(item):\n",
    "    try:\n",
    "        response = requests.get(f'https://en.wikipedia.org/w/api.php?action=query&prop=pageprops&titles={item}&format=json')\n",
    "        wikidata_id = list(json.loads(response.text)['query']['pages'].values())[0]['pageprops']['wikibase_item']\n",
    "        return wikidata_id\n",
    "    except:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(id):\n",
    "    seen = set()\n",
    "    q = deque([(id, 0)])\n",
    "    client = Client()\n",
    "    retDict = defaultdict(list)\n",
    "    while q:\n",
    "        ent, level = q.popleft()\n",
    "        if ent in seen or level > MAX_LEVEL:\n",
    "            continue\n",
    "        retDict[level].append(ent)\n",
    "        seen.add(ent)\n",
    "        try:\n",
    "            e = client.get(ent if isinstance(ent, str) else ent.id).values()\n",
    "            entities = []\n",
    "            for ent in list(e)[:min(len(e), 20)]:\n",
    "                if isinstance(ent, Entity):\n",
    "                    entities.append(ent)\n",
    "            for entity in entities:\n",
    "                q.append((entity, level + 1))\n",
    "        except:\n",
    "            continue\n",
    "    return retDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {0: ['Q36215'],\n",
       "             1: [<wikidata.entity.Entity Q9192 'Mandarin'>,\n",
       "              <wikidata.entity.Entity Q6581097 'male'>,\n",
       "              <wikidata.entity.Entity Q462177 'White Plains'>,\n",
       "              <wikidata.entity.Entity Q5482740 'programmer'>,\n",
       "              <wikidata.entity.Entity Q13371 'Harvard University'>,\n",
       "              <wikidata.entity.Entity Q17290934 'Lentapedia'>,\n",
       "              <wikidata.entity.Entity Q13610143 'Mark'>,\n",
       "              <wikidata.entity.Entity Q83364 'vegetarianism'>],\n",
       "             2: [<wikidata.entity.Entity Q34770 'language'>,\n",
       "              <wikidata.entity.Entity Q6205368 'Category:Mandarin Chinese'>,\n",
       "              <wikidata.entity.Entity Q7850 'Chinese'>,\n",
       "              <wikidata.entity.Entity Q8201 'Chinese characters'>,\n",
       "              <wikidata.entity.Entity Q651641 'subject–verb–object'>,\n",
       "              <wikidata.entity.Entity Q10948482 'Mandarin'>,\n",
       "              <wikidata.entity.Entity Q12308941 'male given name'>,\n",
       "              <wikidata.entity.Entity Q6581072 'female'>,\n",
       "              <wikidata.entity.Entity Q8441 'man'>,\n",
       "              <wikidata.entity.Entity Q48264 'gender identity'>,\n",
       "              <wikidata.entity.Entity Q7905582 'Category:Male'>,\n",
       "              <wikidata.entity.Entity Q20686840 'male and female'>,\n",
       "              <wikidata.entity.Entity Q99485732 'gendered'>,\n",
       "              <wikidata.entity.Entity Q1025294 'Mevaseret Zion'>,\n",
       "              <wikidata.entity.Entity Q15063611 'city in the state of New York'>,\n",
       "              <wikidata.entity.Entity Q54066 'Westchester County'>,\n",
       "              <wikidata.entity.Entity Q7400630 'Category:White Plains, New York'>,\n",
       "              <wikidata.entity.Entity Q30 'United States of America'>,\n",
       "              <wikidata.entity.Entity Q16345303 'Category:Births in White Plains, New York'>,\n",
       "              <wikidata.entity.Entity Q9220391 'Category:Deaths in White Plains, New York'>,\n",
       "              <wikidata.entity.Entity Q8076396 'Category:People from White Plains, New York'>,\n",
       "              <wikidata.entity.Entity Q6624060 'Category:Computer programmers'>,\n",
       "              <wikidata.entity.Entity Q28640 'profession'>,\n",
       "              <wikidata.entity.Entity Q80006 'computer programming'>,\n",
       "              <wikidata.entity.Entity P1056 'product or material produced or service provided'>,\n",
       "              <wikidata.entity.Entity Q183888 'software developer'>,\n",
       "              <wikidata.entity.Entity P943 'programmer'>,\n",
       "              <wikidata.entity.Entity Q128751 'source code'>,\n",
       "              <wikidata.entity.Entity Q902104 'private university'>,\n",
       "              <wikidata.entity.Entity Q8505919 'Category:Harvard University'>,\n",
       "              <wikidata.entity.Entity Q7737 'Russian'>,\n",
       "              <wikidata.entity.Entity Q658909 'lenta.ru'>,\n",
       "              <wikidata.entity.Entity Q159 'Russia'>,\n",
       "              <wikidata.entity.Entity Q15042457 'תבנית:לנטה-פדיה'>,\n",
       "              <wikidata.entity.Entity Q5292 'encyclopedia'>,\n",
       "              <wikidata.entity.Entity Q47461344 'written work'>,\n",
       "              <wikidata.entity.Entity Q17311605 'Lentapedia (full versions)'>,\n",
       "              <wikidata.entity.Entity Q1321 'Spanish'>,\n",
       "              <wikidata.entity.Entity Q6766392 'Mark'>,\n",
       "              <wikidata.entity.Entity Q15728956 'Márkus'>,\n",
       "              <wikidata.entity.Entity Q2531 'April 25'>,\n",
       "              <wikidata.entity.Entity Q6016699 'Mark'>,\n",
       "              <wikidata.entity.Entity Q8229 'Latin script'>,\n",
       "              <wikidata.entity.Entity Q21644845 'frequency of first names in the Netherlands, 2010'>,\n",
       "              <wikidata.entity.Entity Q109671932 'Mark'>,\n",
       "              <wikidata.entity.Entity Q32090 'lifestyle'>,\n",
       "              <wikidata.entity.Entity Q7472978 'Category:Vegetarianism'>,\n",
       "              <wikidata.entity.Entity Q19679809 'Portal:Vegetarianism'>]})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = get_wikidata_id('Mark Zuckerberg')\n",
    "x = bfs(id)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_training_embeddings(labels_file, embeddings_file):\n",
    "    def __remove_at__(l : str):\n",
    "        if '@en' in l:\n",
    "            return l.replace('@en', '')\n",
    "        return l\n",
    "\n",
    "    retVal = {}\n",
    "    with open(labels_file) as labels, open(embeddings_file) as embeddings: \n",
    "        i = 0\n",
    "        curr_label, line_num = labels.readline().split('\\t')\n",
    "        line_num = int(line_num)\n",
    "        curr_label = __remove_at__(curr_label)\n",
    "        for line in embeddings:\n",
    "            if i == line_num:\n",
    "                if curr_label not in retVal:\n",
    "                    retVal[curr_label] = line.strip()\n",
    "                try:\n",
    "                    curr_label, line_num = labels.readline().split('\\t')\n",
    "                    line_num = int(line_num)\n",
    "                    curr_label = __remove_at__(curr_label)\n",
    "                except:\n",
    "                    break\n",
    "            i += 1\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_embedding = get_training_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = pd.DataFrame(columns=['1st', '2nd', '3rd'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
