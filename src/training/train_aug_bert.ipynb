{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for fine-tuning BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\giabr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\giabr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gc import collect\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import cuda\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data\n",
    "\n",
    "data_train = pd.read_csv(r'D:\\programs\\KGA_Bert\\data\\glue_data\\SST-2\\train.tsv', sep='\\t', header=0)\n",
    "data_dev = pd.read_csv(r'D:\\programs\\KGA_Bert\\data\\glue_data\\SST-2\\dev.tsv', sep='\\t', header=0)\n",
    "data_train = data_train.sample(frac = 1, ignore_index=True)\n",
    "data_dev = data_dev.sample(frac = 1, ignore_index=True)\n",
    "\n",
    "embedding_table = pd.read_csv(r\"D:\\programs\\KGA_Bert\\data\\KG_data\\embedding_table.csv\", index_col=0, delimiter='|',\n",
    "                    converters={\n",
    "                        '1' : lambda x: np.array(x.removeprefix('[').removesuffix(']').split(','), dtype='float'),\n",
    "                        '2' : lambda x: np.array(x.removeprefix('[').removesuffix(']').split(','), dtype='float'),\n",
    "                        '3' : lambda x: np.array(x.removeprefix('[').removesuffix(']').split(','), dtype='float')\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LEN = len(max(data_train.sentence, key=len))\n",
    "MAX_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 0.0001\n",
    "NUM_OUT = 1\n",
    "EMBEDDING_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "train_data = pd.DataFrame({\n",
    "    'sentence' : data_train['sentence'].apply(str.strip),\n",
    "    'label' : data_train['label'].apply(int)\n",
    "}).reset_index()\n",
    "\n",
    "test_data = pd.DataFrame({\n",
    "    'sentence' : data_dev['sentence'].apply(str.strip),\n",
    "    'label' : data_dev['label'].apply(int)\n",
    "}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nouns(sentence):\n",
    "    #print(type(sentence))\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tags = nltk.pos_tag(tokens)\n",
    "    retVal = []\n",
    "    i = 0\n",
    "    while i < len(tags):\n",
    "        key, tag = tags[i]\n",
    "        if 'NN' in tag:\n",
    "            retVal.append(key)\n",
    "        i += 1\n",
    "    return retVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer, max_size):\n",
    "        self.sentences = dataset['sentence']\n",
    "        self.labels = dataset['label']\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_size = max_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.sentences[idx]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_size,\n",
    "            pad_to_max_length=True,\n",
    "            truncation=True,\n",
    "            return_token_type_ids=True\n",
    "        )\n",
    "\n",
    "        return {'sentences' : torch.tensor(inputs['input_ids'], dtype=torch.long, device=device),\n",
    "                'raw_text' : text,\n",
    "                'mask' : torch.tensor(inputs['attention_mask'], dtype=torch.long, device=device),\n",
    "                'token_type_ids': torch.tensor(inputs[\"token_type_ids\"], dtype=torch.long, device=device),\n",
    "                'labels' : torch.tensor(self.labels[idx], dtype=torch.float, device=device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultBERTClass(torch.nn.Module):\n",
    "\n",
    "    def __init__(self) -> None:\n",
    "        super(DefaultBERTClass, self).__init__()\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained(\n",
    "            \"bert-base-uncased\"\n",
    "            )\n",
    "        #self.dropout = torch.nn.Dropout(p=0.3)\n",
    "        self.hidd = torch.nn.Linear(self.bert_layer.config.hidden_size + EMBEDDING_LENGTH, NUM_OUT)\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, text, raw_text, attention_mask, token_type_ids):\n",
    "        \n",
    "        embeddings = self.bert_layer(text, attention_mask = attention_mask)\n",
    "        pooler = embeddings[0][:, 0]\n",
    "\n",
    "        new_pooler = None\n",
    "\n",
    "        # Concat Embeddings\n",
    "        for i in range(len(raw_text)):\n",
    "            noun_embeddings = np.zeros(200)\n",
    "            length = 0\n",
    "            sentence = raw_text[i]\n",
    "            for noun in get_nouns(sentence):\n",
    "                if noun in embedding_table.index:\n",
    "                    noun_embeddings += ((1/2) * embedding_table.loc[noun][\"1\"] + (1/3) * embedding_table.loc[noun][\"2\"] + (1/6) * embedding_table.loc[noun][\"3\"])\n",
    "                    length += 1\n",
    "            if length != 0:\n",
    "                noun_embeddings /= length\n",
    "            noun_embeddings = torch.from_numpy(noun_embeddings).to(device)\n",
    "            concat_layer = torch.cat([pooler[i], noun_embeddings]).resize(1, self.bert_layer.config.hidden_size + EMBEDDING_LENGTH)\n",
    "            new_pooler = concat_layer if new_pooler is None else torch.cat([new_pooler, concat_layer], dim=0)\n",
    "\n",
    "        temp = new_pooler.float()\n",
    "\n",
    "        hidden = self.hidd(temp)\n",
    "        \n",
    "        output = self.sig(hidden)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def loss_fn(outputs, targets):\n",
    "    return torch.nn.BCELoss()(outputs, targets)\n",
    "\n",
    "def train(model, optimizer, data_loader):\n",
    "    model.train()\n",
    "    for data in tqdm(data_loader):\n",
    "        inputs = data['sentences']\n",
    "        raw_text = data['raw_text']\n",
    "        mask = data['mask']\n",
    "        token_type_ids = data['token_type_ids']\n",
    "        targets = data['labels'].unsqueeze(1)\n",
    "\n",
    "        outputs = model(inputs, raw_text, mask, token_type_ids)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(outputs, targets)\n",
    "        #optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Memory optimization\n",
    "        del inputs, mask, token_type_ids, targets, raw_text\n",
    "        collect()\n",
    "        with torch.cuda.device(device):\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    return loss\n",
    "\n",
    "def validation(model, data_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(data_loader):\n",
    "            inputs = data['sentences']\n",
    "            raw_text = data['raw_text']\n",
    "            mask = data['mask']\n",
    "            token_type_ids = data['token_type_ids']\n",
    "            targets = data['labels'].unsqueeze(1)\n",
    "\n",
    "            outputs = model(inputs, raw_text, mask, token_type_ids)\n",
    "\n",
    "            del inputs, mask, token_type_ids, raw_text\n",
    "            collect()\n",
    "            with torch.cuda.device(device):\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "            fin_outputs.extend(outputs)\n",
    "            fin_targets.extend(targets)\n",
    "\n",
    "    return torch.stack(fin_outputs), torch.stack(fin_targets)\n",
    "\n",
    "def get_accuracy(guess, targs):\n",
    "    guesses = (guess >= 0.5).cpu().numpy()\n",
    "    targets = (targs >= 0.5).cpu().numpy()\n",
    "    return accuracy_score(guesses, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "training_data = CustomDataset(train_data, tokenizer, MAX_LEN)\n",
    "training_loader = DataLoader(training_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "testing_data = CustomDataset(test_data, tokenizer, MAX_LEN)\n",
    "testing_loader = DataLoader(testing_data, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def live_plot(accuracies):\n",
    "    clear_output(wait=True)\n",
    "    plt.figure()\n",
    "    plt.xlim(0, EPOCHS)\n",
    "    plt.ylim(0, 1)\n",
    "    x= [float(i) for i in range(len(accuracies))]\n",
    "    y= [float(i) for i in accuracies]\n",
    "    \n",
    "    if len(x) > 1:\n",
    "        plt.plot(x,y)\n",
    "\n",
    "    plt.grid(True)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test set 0.5126146788990825\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa640816e473434facea34ec1aad45b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giabr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n",
      "c:\\Users\\giabr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:836: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Loss:  0.6631485819816589\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80081be5295a44ab8c3a3c0d5bea853a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m train(model, optimizer, training_loader)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Loss:  \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 11\u001b[0m guess, targs \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtesting_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m#print(guess, targs)\u001b[39;00m\n\u001b[0;32m     15\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m get_accuracy(guess, targs)\n",
      "Cell \u001b[1;32mIn[9], line 43\u001b[0m, in \u001b[0;36mvalidation\u001b[1;34m(model, data_loader)\u001b[0m\n\u001b[0;32m     40\u001b[0m token_type_ids \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     41\u001b[0m targets \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs, mask, token_type_ids\n\u001b[0;32m     46\u001b[0m collect()\n",
      "File \u001b[1;32mc:\\Users\\giabr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\giabr\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 32\u001b[0m, in \u001b[0;36mDefaultBERTClass.forward\u001b[1;34m(self, text, raw_text, attention_mask, token_type_ids)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m length \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     31\u001b[0m     noun_embeddings \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m length\n\u001b[1;32m---> 32\u001b[0m noun_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnoun_embeddings\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m concat_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([pooler[i], noun_embeddings])\u001b[38;5;241m.\u001b[39mresize(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbert_layer\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mhidden_size \u001b[38;5;241m+\u001b[39m EMBEDDING_LENGTH)\n\u001b[0;32m     34\u001b[0m new_pooler \u001b[38;5;241m=\u001b[39m concat_layer \u001b[38;5;28;01mif\u001b[39;00m new_pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat([new_pooler, concat_layer], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = DefaultBERTClass()\n",
    "optimizer = torch.optim.SGD(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "validation_accuracies = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    loss = train(model, optimizer, training_loader)\n",
    "    print(f'Epoch: {epoch}, Loss:  {loss.item()}')\n",
    "    guess, targs = validation(model, testing_loader)\n",
    "\n",
    "    #print(guess, targs)\n",
    "    \n",
    "    accuracy = get_accuracy(guess, targs)\n",
    "    validation_accuracies.append(accuracy)\n",
    "\n",
    "    live_plot(validation_accuracies)\n",
    "\n",
    "    print('accuracy on test set {}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
